\documentclass{hw}
\title{Research Report}
\author{Brandon, Jake, Michael, Rene}

\usepackage{xcolor}

\newcommand{\netauto}{\texttt{netkat-automata}}
\newcommand{\niceref}[2]{\underline{\textcolor{blue}{\href{#1}{#2}}}}

\begin{document}
\maketitle

\section{Background}
Last semester, we designed and implemented Felix: a system which measures
network traffic using NetKAT. The design of Felix's query language and
compilation algorithm was complete, and a paper on Felix was accepted to SOSR.
However, both Felix and the SOSR submission were imperfect. Felix's query
compiler was slow when run on large inputs and would often crash when run on
\emph{very} large inputs. The Felix compiler was not integrated with Haoxian's
runtime which made it onerous to run Felix end-to-end. Finally, our SOSR
submission was written hurriedly and submitted last
minute\footnote{literally!}, leaving the paper a bit incohesive.

\section{Getting Felix Camera-Ready}
The bulk of this semester was spent fixing these imperfections. We optimized
the Felix compiler, integrated the compiler with the runtime, conducted new
case studies, revised the paper, and ultimately presented Felix at SOSR!

\subsection{Optimization}
\paragraph{Hashconsing}
The Felix compiler uses the FDD implementation in the \netauto{} repository
which hashconses NetKAT terms to avoid redundant storage and computation.
However, a couple of performance critical pieces of code did not take advantage
of the hashconsing. Notably, the computation of a term's hash was recomputing
the hash of all of its subterms! When compiling against very large topologies,
this became a bottleneck. We refactored the code to take advantage of
hashconsing which improved the performance of the compiler considerably.
Moreover, we replaced the \netauto{} implementation of hashconsing with an
\niceref{https://github.com/backtracking/ocaml-hashcons}{optimized library
implementation}.

\paragraph{CPS}
Our SOSR submission included some Felix benchmarks that were run against
\emph{every} topology in the Topology Zoo. Well, almost every. A footnote in
the paper explained that Felix crashed on a few of the larger topology. After
some debugging, we found that a certain recursive function was overflowing the
stack. We rewrote the function using CPS and were then able to run on all of
Topology Zoo!

\paragraph{Predicate Splitting}
In our benchmarks, we assumed that each topology was implemented with a simple
destination-based shortest path routing policy: the path each packet took was
determined completely by its source and destination.  We exploited the
simplicity of the forwarding policy to improve compile times.  Given a
forwarding policy $p$ and a network with $n$ hosts, we partitioned $p$ into a
$n$ sub-policies $p_1, \ldots, p_n$ where $p_i$ included only the forwarding
rules forwarding to host $i$. We then compiled each sub-policy separately
before combining the results.

After implementing these optimizations, the query compiler ran between 10 and
100 times faster! The time to compile some queries and topologies was reduced
from hours to minutes.

\subsection{Integration}
We integrated our query compiler with Haoxian's end-host measurement system.
The compiler outputed the set of $(\alpha, \beta)$ pairs read from the
E-matrix.  We converted these pairs into configurations for the end-host
monitors. We worked with Haoxian to extend the end-host measurement system to
allow packet tagging. To tag packets, we assigned each $\alpha$ a unique
identifier to tag packets that matched $\alpha$. For each $(\alpha, \beta)$
pair, we configured all end hosts to count a received packet if it matched
$\beta$ and was tagged with the identifier corresponding to $\alpha$.  We were
also able to use this system to generate traffic matrices since Haoxian's
measurement system already supported keeping track of counts of
source-destination pairs.

\subsection{Experimentation}
After we integrated the compiler and runtime, we were able to design and
conduct two new case studies. Using mininet and iperf to virtualize networks
and synthesize traffic, we generated traffic matrices over the ARPANet topology
and dissected a more complex traffic pattern over the Abilene topology. We also
re-ran our original benchmarks with the newly optimized code.

\subsection{Revision}
In addition to revising and benchmarking Felix's implementation, we also
wrestled our SOSR submission into camera-ready form. Though, we can't take too
much credit for this; Nate did most of the heavy lifting!

\subsection{Presentation}
After a semester or so of designing, implementing, and polishing Felix, we were
able to proudly show off our work! We prepared and presented a 25 minute
presentation at SOSR.

\section{Integrating Code}
The ideas underlying the frenetic, \netauto{}, and Felix code bases are cut
from the same cloth, but the code itself is very fragmented. The \netauto{}
repository implements its own type for NetKAT terms, its own lexer and parser,
its own FDDs, and its own REPL. Felix is a fork of the \netauto{} code and
introduces yet another set of terms (i.e. queries) and a new REPL. Living
outside the main frenetic repository, both the \netauto{} and Felix code are
also seldom built and the students who have worked on them have mostly
graduated or are graduating.

We have begun integrating the \netauto{} and Felix code into the main frenetic
codebase. All the code has been plopped into the main repository and integrated
with its build system. Deprecated and abandoned files have been deleted. Most
notably, the frenetic and \netauto{} REPLs have been discarded, and the main
frenetic shell can now invoke both Felix and the NetKAT decision procedure.

\section{Future Work}
\paragraph{Finishing Integration}
There a few major steps left in integrating all the code into the main frenetic
repository. We will work on this over the summer.
\begin{itemize}
  \item
    We need to replace the \netauto{} implementation of FDDs with the frenetic
    implementation of FDDs.
  \item
    We need to replace the \netauto{} implementation of NetKAT terms with the
    frenetic implementation, or translate between the two. This will also
    involve merging the lexers and parsers.
  \item
    We need to polish the frenetic shell to make it easy to run the NetKAT
    decision procedure and Felix compiler.
\end{itemize}

\paragraph{An Abominable Snowman}
The implementation of FDDs in the current \netauto{} code has a peculiar bug in
which a unicode snowman is printed. The dreaded snowman was hardcoded to
indicate that something in the code has gone wrong. We have plans to fix this
bug, but the snowman code may be deleted entirely when we finish integrating
the \netauto{} code into the frenetic repository.

\paragraph{Research Directions}
Moving forward, there are a handful of research topics we have discussed over
the year that remain unanswered. Most notably, Felix assumes the network
behaves exactly as specified by its forwarding policy. Felix is oblivious to
network misbehavior. However, it may be possible to leverage Felix to
dynamically verify that the network is behaving as specified. For example, if
each switch recorded each and every packet that it processed, how it was
modified, and where it was forwarded, we could easily verify the behavior of
the network. Of course, this solution is a bit heavy handed. What is the
minimal amount of instrumentation or network functionality needed to check that
the network is behaving correctly? One conjecture was that per-link packet
counts would suffice. Other research directions are outlined in the conclusion
of our SOSR paper.
\end{document}
