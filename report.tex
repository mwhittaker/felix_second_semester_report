\documentclass{hw}
\title{Research Report}
\author{Brandon, Jake, Michael, Rene}

\newcommand{\netauto}{\texttt{netkat-automata}}

\begin{document}
\maketitle

\section{Background}
Last semester, we designed and implemented Felix: a system which measures
network traffic using NetKAT. Felix's query language and query compilation
design were complete, and a paper on Felix was accepted to SOSR. However,
both Felix and the SOSR submission were imperfect. First, Felix's query
compiler was slow for large inputs and would often crash on \emph{very} large
inputs. Second, the Felix compiler was not integrated with Haoxian's runtime
which made it onerous to run Felix end-to-end. Finally, our SOSR submission was
written hurriedly and submitted last minute\footnote{literally!}, leaving the
paper a bit incohesive.

\section{Getting Felix Camera-Ready}
The bulk of this semester was spent fixing these imperfections. We optimized
the Felix compiler, integrated the compiler with the runtime, conducted new
benchmarks and case studies, revised the paper, and ultimately presented Felix
at SOSR!

\subsection{Optimization}
\paragraph{Hashconsing}
The Felix compiler uses the FDD implementation in the \netauto{} repository
which hashconses NetKAT terms to avoid redundant storage and computation.
However, a couple of performance critical pieces of code did not take advantage
of the hashconsing. Notably, the computation of a term's hash was recomputing
the hash of all of its subterms! When compiling against very large topologies,
this became a bottleneck. We refactored the code to take advantage of
hashconsing which improved the performance of the compiler considerably.
Moreover, we replaced the \netauto{} implementation of hashconsing with an
optimized library implementation.
% https://github.com/backtracking/ocaml-hashcons

\paragraph{CPS}
Our SOSR submission included some Felix benchmarks run against every topology
in the Topology Zoo. Well, almost. A footnote in the paper explained that Felix
crashed on a few of the larger topology. After some debugging, we found that a
certain recursive function was overflowing the stack. We rewrote the function
using CPS and were then able to run on all of Topology Zoo!

\paragraph{Predicate Splitting}
In our benchmarks against the topology zoo, we assumed each topology was
implemented with a simple destination-based shortest path routing policy. The
path each packet took was determined completely by its source and destination.
We exploited the simplicity of the forwarding policy to improve compile times.
Given a forwarding policy $p$ and a network with $n$ hosts, we partitioned $p$
into a $n$ sub-policies $p_1, \ldots, p_n$ where $p_i$ included only the
forwarding rules forwarding to host $i$. We then compiled each sub-policy
separately before combining the results.

After implementing these optimizations, the query compiler ran between 10 and
100 times faster! The compilation time for some queries and topologies was
reduced from hours to minutes.

\subsection{Integration}
We integrated our query compiler with Haoxian's end-host measurement system.
The compiler outputs the set of $(\alpha, \beta)$ pairs read from the E-matrix.
We converted these pairs into configurations for the end-host monitors. We
worked with Haoxian to extend the end-host measurement system to allow packet
tagging. To tag packets, we assigned each $\alpha$ a unique identifier to tag
packets that matched $\alpha$. For each $(\alpha, \beta)$ pair, we configured
all end hosts to count a received packet if it matched $\beta$ and was tagged
with the identifier corresponding to $\alpha$.  We were also able to use this
system to generate traffic matrices since Haoxian's measurement system already
supported keeping track of counts of source-destination pairs.

\subsection{Experimentation}
After we integrated the compiler and runtime, we were able to design and
conduct two new case studies. Using mininet and iperf to virtualize networks
and synthesize traffic, we generated traffic matrices over the ARPANet topology
and dissected a more complex traffic pattern over the Abilene topology. We also
re-ran our original benchmarks with the newly optimized code.

\subsection{Revision}
In addition to revising and benchmarking Felix's implementation, we also
wrestled our SOSR submission into camera-ready form. Though, we can't take too
much credit for this; Nate did most of the heavy lifting!

\subsection{Presentation}
After a semester or so of designing, implementing, and polishing Felix, we were
able to proudly show off our work! We prepared and presented a 25 minute
presentation at SOSR.

\section{Integrating Code}
The ideas underlying the frenetic, \netauto{}, and Felix code bases are cut
from the same cloth, but the code itself is very fragmented. The \netauto{}
repository implements its own type for NetKAT terms, its own lexer and parser,
its own FDDs, and its own REPL. Felix is fork of the \netauto{} code and
introduces yet another set of terms (i.e. queries) and a new REPL. Living
outside the main frenetic repository, both the \netauto{} and Felix code are
also seldom built and the students who have worked on them have mostly
graduated or are graduating.

We have begun integrating the \netauto{} and Felix code into the main frenetic
codebase. All the code has been plopped into the main repository and integrated
with its build system. Deprecated and abandoned files have been deleted. Most
notably, the frenetic and \netauto{} REPLs have been discarded, and the main
frenetic shell can now invoke both Felix and the NetKAT decision procedure.

\section{Future Work}
\paragraph{Finishing Integration}
There a few major steps left in integrating all the code into the main frenetic
repository. We will work on this over the summer.
\begin{itemize}
  \item
    We need to replace the \netauto{} implementation of FDDs with the frenetic
    implementation of FDDs.
  \item
    We need to replace the \netauto{} implementation of NetKAT terms with the
    frenetic implementation or translate between the two. This will also
    involve merging the lexer and parsers.
  \item
    We need to polish the frenetic shell to make it easy to run the NetKAT
    decision procedure and Felix compiler.
\end{itemize}

\paragraph{An Abominable Snowman}
The implementation of FDDs in the current \netauto{} code has a peculiar bug in
which a unicode snowman is printed. The dreaded snowman was hardcoded to
indicate that something in the code has gone wrong. We have plans to fix this
bug, but the snowman code may be deleted entirely when we finish integrating
the \netauto{} code into the frenetic repo.

\paragraph{Research Directions}
% finish integrating code
% snowman
% ???; whoever was at these meetings:
%   - detecting cycles and black holes
%   - checking counts with minimal instrumentation
\end{document}
